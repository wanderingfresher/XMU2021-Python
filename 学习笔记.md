大致步骤

1. 发起请求

​		通过http库向目标站点发起请求,request  可以包含额外的headers,data等信息,

```python
headers = {
    # 'wd':key_word,
    # 'Host': 'https://baike.baidu.com/item/',
    "User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36"
}
```



因为现在爬虫非常多，各个网站也都增加了相应的反爬虫机制，我们就必须在爬取时模拟真人的操

作。在requests.get中加入了请求头（headers），就可以很好的绕过服务器的检查。

2、加上html.encoding = html.apparent_encoding这句话了是为了把页面转化为我们所能理解的方

式。

```python
key_word = urllib.parse.quote(key_word,encoding = 'utf-8', errors = 'replace')

```

parse为解析功能

quote为编码功能

errors是为了替换加上 ’ % '功能



2. 获取响应

​		服务器正常响应,得到response反馈,类型可能不同,

3. 解析内容

​		往往用解析库处理,处理对象内容

4. 保存数据





分类

通用爬虫   与   聚焦爬虫





我们的爬取的内容是：电影详情链接，图片链接，影片中文名，影片外国名，评分，评价数，概况，相关信息。